llama-server \
    -m unsloth_Qwen3.5-35B-A3B-GGUF_Qwen3.5-35B-A3B-UD-Q4_K_XL.gguf \
    --mmproj unsloth_Qwen3.5-35B-A3B-GGUF_mmproj-BF16.gguf \
    --ctx-size 16384 \
    --temp 1.0 \
    --top-p 0.95 \
    --top-k 20 \
    --min-p 0.00 \
    --chat-template-kwargs "{\"enable_thinking\": false}" \
    --host 0.0.0.0 \
    --port 8082